---
title: "Artificial Intelligence"
date: 2025-05-26
draft: false
---

This is an attempt to continue learning and understanding Artificial Intelligence. There was a time when Computer Science used to be part of Electronics Engineering. At some point in time, most of Electronics Engineering industry became about computer science. Artificial Intelligence has done the same thing to Computer Science.

Every Software Engineer or Computer Scientist have to become expert in Artificial Intelligence.

I am going to use this space to log topics that I have learnt and have to learn.


### Foundation Models/Transformers
- [ ] "Attention Is All You Need" - The original transformer paper; implementing this will teach you core concepts used in modern LLMs
- [ ] "BERT: Pre-training of Deep Bidirectional Transformers" - A manageable yet powerful NLP architecture
- [ ] "Vision Transformer (ViT)" - Applies transformers to computer vision
- [ ] Evals
- [ ] Reinforcement Learning in LLMs https://chatgpt.com/c/683541e3-8a30-8001-8006-b599ef27bbec

### Generative Models
- [ ] "Variational Autoencoder" - A good entry point into generative models
- [ ] "DCGAN: Unsupervised Representation Learning with Deep Convolutional GANs" - Relatively simple GAN architecture
- [ ] "Denoising Diffusion Probabilistic Models" - More challenging but extremely relevant given recent advances

### Reinforcement Learning

- [ ] "Playing Atari with Deep Reinforcement Learning" - DQN, a good starting point for deep RL
- [ ] "Proximal Policy Optimization" - A standard algorithm that's simpler than some alternatives
